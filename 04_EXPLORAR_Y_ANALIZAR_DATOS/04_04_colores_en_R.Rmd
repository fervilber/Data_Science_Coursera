---
title: "Colores en R"
author: "Fernando Villalba"
date: "13 de febrero de 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
$\pagebreak$

## Color Packages in R Plots
* proper use of color can help convey the message by improving clarity/contrast of data presented
* default color schemes for most plots in R are fairly terrible, so some external packages are helpful

### `grDevices` Package
* `colors()` function = lists names of colors available in any plotting function
* **`colorRamp` function**
	- takes any set of colors and return a function that takes values between 0 and 1, indicating the extremes of the color palette (e.g. see the `gray` function)
	- `pal <- colorRamp(c("red", "blue"))` = defines a `colorRamp` function
	- `pal(0)` returns a 1 x 3 matrix containing values for RED, GREEN, and BLUE values that range from 0 to 255
	- `pal(seq(0, 1, len = 10))` returns a 10 x 3 matrix of 10 colors that range from RED to BLUE (two ends of spectrum defined in the object)
	- ***example***

```{r}
# define colorRamp function
pal <- colorRamp(c("red", "blue"))
# create a color
pal(0.67)
```

* **`colorRampPalette` function**
	- takes any set of colors and return a function that takes integer arguments and returns a vector of colors interpolating the palette (like `heat.colors` or `topo.colors`)
	- `pal <- colorRampPalette(c("red", "yellow"))` defines a `colorRampPalette` function
	- `pal(10)` returns 10 interpolated colors in hexadecimal format that range between the defined ends of spectrum
	- ***example***

```{r}
# define colorRampPalette function
pal <- colorRampPalette(c("red", "yellow"))
# create 10 colors
pal(10)
```

* **`rgb` function**
	- `red`, `green`, and `blue` arguments = values between 0 and 1
	- `alpha = 0.5` = transparency control, values between 0 and 1
	- returns hexadecimal string for color that can be used in `plot`/`image` commands
	- `colorspace` package `cna` be used for different control over colors
	- ***example***

```{r fig.height = 4, fig.width = 6, fig.align='center'}
x <- rnorm(200); y <- rnorm(200)
par(mfrow=c(1,2))
# normal scatter plot
plot(x, y, pch = 19, main = "Default")
# using transparency shows data much better
plot(x, y, col = rgb(0, 0, 0, 0.2), main = "With Transparency")
```

### `RColorBrewer` Package
* can be found on CRAN that has predefined color palettes
	* `library(RColorBrewer)`
* **types of palettes**
	- *Sequential* = numerical/continuous data that is ordered from low to high
	- *Diverging* = data that deviate from a value, increasing in two directions (i.e. standard deviations from the mean)
	- *Qualitative* = categorical data/factor variables
* palette information from the `RColorBrewer` package can be used by `colorRamp` and `colorRampPalette` functions
* **available colors palettes**

```{r fig.height = 6, fig.width = 8, fig.align='center', echo=FALSE, eval=FALSE}
grid.raster(readPNG("figures/color.png"))
```

* **`brewer.pal(n, "BuGn")` function**
	- `n` = number of colors to generated
	- `"BuGn"` = name of palette
		+ `?brewer.pal` list all available palettes to use
	- returns list of `n` hexadecimal colors
* ***example***

```{r fig.height = 3, fig.width = 7, fig.align='center'}
library(RColorBrewer)
# generate 3 colors using brewer.pal function
cols <- brewer.pal(3, "BuGn")
pal <- colorRampPalette(cols)
par(mfrow=c(1,3))
# heat.colors/default
image(volcano, main = "Heat.colors/Default")
# topographical colors
image(volcano, col = topo.colors(20), main = "Topographical Colors")
# RColorBrewer colors
image(volcano, col = pal(20), main = "RColorBrewer Colors")
```

* **`smoothScatter` function**
	- used to plot large quantities of data points
	- creates 2D histogram of points and plots the histogram
	- default color scheme = "Blues" palette from `RColorBrewer` package
	- ***example***

```{r fig.height = 4, fig.width = 4, fig.align='center'}
x <- rnorm(10000); y <- rnorm(10000)
smoothScatter(x, y)
```


$\pagebreak$

## Case Study: Human Activity Tracking with Smart Phones

**Loading Training Set of Samsung S2 Data from [UCI Repository](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)**


```{r , eval=FALSE}
# load data frame provided
load("samsungData.rda")
# table of 6 types of activities
table(samsungData$activity)
```

**Plotting Average Acceleration for First Subject**

```{r fig.height=4,fig.width=7, fig.align='center', eval=FALSE}
# set up 1 x 2 panel plot
par(mfrow=c(1, 2), mar = c(5, 4, 1, 1))
# converts activity to a factor variable
samsungData <- transform(samsungData, activity = factor(activity))
# find only the subject 1 data
sub1 <- subset(samsungData, subject == 1)
# plot mean body acceleration in X direction
plot(sub1[, 1], col = sub1$activity, ylab = names(sub1)[1],
	main = "Mean Body Acceleration for X")
# plot mean body acceleration in Y direction
plot(sub1[, 2], col = sub1$activity, ylab = names(sub1)[2],
	main = "Mean Body Acceleration for Y")
# add legend
legend("bottomright",legend=unique(sub1$activity),col=unique(sub1$activity), pch = 1)
```


**Clustering Based on Only Average Acceleration**

```{r fig.height=5,fig.width=7, fig.align='center', eval=FALSE}
# load myplclust function
source("myplclust.R")
# calculate distance matrix
distanceMatrix <- dist(sub1[,1:3])
# form hclust object
hclustering <- hclust(distanceMatrix)
# run myplclust on data
myplclust(hclustering, lab.col = unclass(sub1$activity))
```


**Plotting Max Acceleration for the First Subject**

```{r fig.height=4,fig.width=7, fig.align='center', eval=FALSE}
# create 1 x 2 panel
par(mfrow=c(1,2))
# plot max accelecrations in x and y direction
plot(sub1[,10],pch=19,col=sub1$activity,ylab=names(sub1)[10],
	main = "Max Body Acceleration for X")
plot(sub1[,11],pch=19,col = sub1$activity,ylab=names(sub1)[11],
	main = "Max Body Acceleration for Y")
```


**Clustering Based on Maximum Acceleration**

```{r fig.height=5,fig.width=7, fig.align='center', eval=FALSE}
# calculate distance matrix for max distances
distanceMatrix <- dist(sub1[,10:12])
hclustering <- hclust(distanceMatrix)
myplclust(hclustering,lab.col=unclass(sub1$activity))
```


**Singular Value Decomposition**

```{r fig.height=4,fig.width=7,fig.align='center', cache=TRUE, eval=FALSE}
# perform SVD minus last two columns (subject and activity)
svd1 = svd(scale(sub1[,-c(562,563)]))
# create 1 x 2 panel plot
par(mfrow=c(1,2))
# plot first two left singular vector
# separate moving from non moving
plot(svd1$u[,1],col=sub1$activity,pch=19, main = "First Left Singular Vector")
plot(svd1$u[,2],col=sub1$activity,pch=19, main = "Second Left Singular Vector")
```


**New Clustering with Maximum Contributers**

```{r fig.height=5,fig.width=7,fig.align='center', eval=FALSE}
# find the max contributing feature
maxContrib <- which.max(svd1$v[,2])
# recalculate distance matrix
distanceMatrix <- dist(sub1[, c(10:12,maxContrib)])
hclustering <- hclust(distanceMatrix)
myplclust(hclustering,lab.col=unclass(sub1$activity))
# name of max contributing factor
names(samsungData)[maxContrib]
```


**K-means Clustering (nstart=1, first try)**

```{r, eval=FALSE}
# specify 6 centers for data
kClust <- kmeans(sub1[,-c(562,563)],centers=6)
# tabulate 6 clusteres against 6 activity but many clusters contain multiple activities
table(kClust$cluster,sub1$activity)
```

**K-means clustering (nstart=100, first try)**

```{r cache=TRUE, eval=FALSE}
# run k-means algorithm 100 times
kClust <- kmeans(sub1[,-c(562,563)],centers=6,nstart=100)
# tabulate results
table(kClust$cluster,sub1$activity)
```

**K-means clustering (nstart=100, second try)**

```{r cache=TRUE, eval=FALSE}
# run k-means algorithm 100 times
kClust <- kmeans(sub1[,-c(562,563)],centers=6,nstart=100)
# tabulate results
table(kClust$cluster,sub1$activity)
```

**Cluster 1 Variable Centers (Laying)**

```{r fig.height=4,fig.width=5, fig.align='center', eval=FALSE}
# plot first 10 centers of k-means for laying to understand which features drive the activity
plot(kClust$center[1,1:10],pch=19,ylab="Cluster Center",xlab="")
```


**Cluster 2 Variable Centers (Walking)**

```{r fig.height=4,fig.width=5, fig.align='center', eval=FALSE}
# plot first 10 centers of k-means for laying to understand which features drive the activity
plot(kClust$center[4,1:10],pch=19,ylab="Cluster Center",xlab="")
```


$\pagebreak$

## Case Study: Fine Particle Pollution in the U.S. from 1999 to 2012

**Read Raw Data from 1999 and 2012**

```{r cache = TRUE, eval=FALSE}
# read in raw data from 1999
pm0 <- read.table("pm25_data/RD_501_88101_1999-0.txt", comment.char = "#", header = FALSE, sep = "|", na.strings = "")
# read in headers/column lables
cnames <- readLines("pm25_data/RD_501_88101_1999-0.txt", 1)
# convert string into vector
cnames <- strsplit(substring(cnames, 3), "|", fixed = TRUE)
# make vector the column names
names(pm0) <- make.names(cnames[[1]])
# we are interested in the pm2.5 readings in the "Sample.Value" column
x0 <- pm0$Sample.Value
# read in the data from 2012
pm1 <- read.table("pm25_data/RD_501_88101_2012-0.txt", comment.char = "#", header = FALSE, sep = "|",
	na.strings = "", nrow = 1304290)
# make vector the column names
names(pm1) <- make.names(cnames[[1]])
# take the 2012 data for pm2.5 readings
x1 <- pm1$Sample.Value
```

**Summaries for Both Periods**

```{r, eval=FALSE}
# generate 6 number summaries
summary(x1)
summary(x0)
# calculate % of missing values, Are missing values important here?
data.frame(NA.1990 = mean(is.na(x0)), NA.2012 = mean(is.na(x1)))
```

**Make a boxplot of both 1999 and 2012**

```{r warning=FALSE, eval=FALSE, fig.width = 7, fig.height = 4, fig.align = 'center'}
par(mfrow = c(1,2))
# regular boxplot, data too right skewed
boxplot(x0, x1, main = "Regular Boxplot")
# log boxplot, significant difference in means, but more spread
boxplot(log10(x0), log10(x1), main = "log Boxplot")
```

**Check for Negative Values in 'x1'**

```{r fig.width = 5, fig.height = 4, fig.align = 'center', eval=FALSE}
# summary again
summary(x1)
# create logical vector for
negative <- x1 < 0
# count number of negatives
sum(negative, na.rm = T)
# calculate percentage of negatives
mean(negative, na.rm = T)
# capture the date data
dates <- pm1$Date
dates <- as.Date(as.character(dates), "%Y%m%d")
# plot the histogram
hist(dates, "month")  ## Check what's going on in months 1--6
```

**Check Same New York Monitors at 1999 and 2012**

```{r, eval=FALSE}
# find unique monitors in New York in 1999
site0 <- unique(subset(pm0, State.Code == 36, c(County.Code, Site.ID)))
# find unique monitors in New York in 2012
site1 <- unique(subset(pm1, State.Code == 36, c(County.Code, Site.ID)))
# combine country codes and siteIDs of the monitors
site0 <- paste(site0[,1], site0[,2], sep = ".")
site1 <- paste(site1[,1], site1[,2], sep = ".")
# find common monitors in both
both <- intersect(site0, site1)
# print common monitors in 1999 and 2012
print(both)
```

**Find how many observations available at each monitor**

```{r, eval=FALSE}
# add columns for combined county/site for the original data
pm0$county.site <- with(pm0, paste(County.Code, Site.ID, sep = "."))
pm1$county.site <- with(pm1, paste(County.Code, Site.ID, sep = "."))
# find subsets where state = NY and county/site = what we found previously
cnt0 <- subset(pm0, State.Code == 36 & county.site %in% both)
cnt1 <- subset(pm1, State.Code == 36 & county.site %in% both)
# split data by the county/size values and count oberservations
sapply(split(cnt0, cnt0$county.site), nrow)
sapply(split(cnt1, cnt1$county.site), nrow)
```

**Choose Monitor where County = 63 and Side ID = 2008**

```{r, eval=FALSE}
# filter data by state/county/siteID
pm1sub <- subset(pm1, State.Code == 36 & County.Code == 63 & Site.ID == 2008)
pm0sub <- subset(pm0, State.Code == 36 & County.Code == 63 & Site.ID == 2008)
# there are 30 observations from 2012, and 122 from 1999
dim(pm1sub)
dim(pm0sub)
```

**Plot Data for 2012**

```{r fig.width=4, fig.height=4, fig.align = 'center', eval=FALSE}
# capture the dates of the subset of data
dates1 <- pm1sub$Date
# capture measurements for the subset of data
x1sub <- pm1sub$Sample.Value
# convert dates to appropriate format
dates1 <- as.Date(as.character(dates1), "%Y%m%d")
# plot pm2.5 value vs time
plot(dates1, x1sub, main = "PM2.5 Polution Level in 2012")
```

**Plot data for 1999**

```{r fig.width=4, fig.height=4, fig.align = 'center', eval=FALSE}
# capture the dates of the subset of data
dates0 <- pm0sub$Date
# convert dates to appropriate format
dates0 <- as.Date(as.character(dates0), "%Y%m%d")
# capture measurements for the subset of data
x0sub <- pm0sub$Sample.Value
# plot pm2.5 value vs time
plot(dates0, x0sub, main = "PM2.5 Polution Level in 1999")
```

**Panel Plot for Both Years**

```{r fig.width=6, fig.height=4, fig.align = 'center', eval=FALSE}
# find max range for data
rng <- range(x0sub, x1sub, na.rm = T)
# create 1 x 2 panel plot
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))
# plot time series plot for 1999
plot(dates0, x0sub, pch = 20, ylim = rng, main="Pollution in 1999")
# plot the median
abline(h = median(x0sub, na.rm = T))
# plot time series plot for 2012
plot(dates1, x1sub, pch = 20, ylim = rng, main="Pollution in 2012")
# plot the median
abline(h = median(x1sub, na.rm = T))
```

**Find State-wide Means and Trend**

```{r fig.width=5, fig.height=5, fig.align = 'center', eval=FALSE}
# divide data by state and find tne mean of pollution level for 1999
mn0 <- with(pm0, tapply(Sample.Value, State.Code, mean, na.rm = T))
# divide data by state and find tne mean of pollution level for 1999
mn1 <- with(pm1, tapply(Sample.Value, State.Code, mean, na.rm = T))
# convert to data frames while preserving state names
d0 <- data.frame(state = names(mn0), mean = mn0)
d1 <- data.frame(state = names(mn1), mean = mn1)
# merge the 1999 and 2012 means by state
mrg <- merge(d0, d1, by = "state")
# dimension of combined data frame
dim(mrg)
# first few lines of data
head(mrg)

# plot the pollution levels data points for 1999
with(mrg, plot(rep(1, 52), mrg[, 2], xlim = c(.8, 2.2), ylim = c(3, 20),
	main = "PM2.5 Pollution Level by State for 1999 & 2012",
	xlab = "", ylab = "State-wide Mean PM"))
# plot the pollution levels data points for 2012
with(mrg, points(rep(2, 52), mrg[, 3]))
# connected the dots
segments(rep(1, 52), mrg[, 2], rep(2, 52), mrg[, 3])
# add 1999 and 2012 labels
axis(1, c(1, 2), c("1999", "2012"))
```
